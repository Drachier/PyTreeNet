{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytreenet as ptn\n",
    "from copy import deepcopy\n",
    "from scipy.linalg import expm\n",
    "from pytreenet.util import copy_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_prime_dict(mps, mps_tilde):\n",
    "    \"\"\"\"\n",
    "    Function to build the A_prime matrixes in A.2\n",
    "    Args:\n",
    "        mps: MPS object\n",
    "        mps_tilde: MPS object\n",
    "    Returns:\n",
    "        tensors_prime: Dictionary with the A_prime matrices\n",
    "    \"\"\"\n",
    "    tensors = []\n",
    "    tensors_prime = {}\n",
    "\n",
    "    # Iterate over the sites\n",
    "    for i in range(len(mps.nodes) - 1):\n",
    "        # Extract the tensors\n",
    "        A1 = mps.tensors[f\"site{i}\"][..., 0]\n",
    "        A1_tilde = mps_tilde.tensors[f\"site{i}\"][..., 0]\n",
    "        A2 = mps.tensors[f\"site{i}\"][..., 1]\n",
    "        A2_tilde = mps_tilde.tensors[f\"site{i}\"][..., 1]\n",
    "\n",
    "        # Combine the tensors\n",
    "        tensors.append(A1 + A2)\n",
    "        tensors.append(A1_tilde + A2_tilde)\n",
    "\n",
    "        # Create the combined tensor\n",
    "        A_0 = np.block([[A1, np.zeros_like(A1)], [np.zeros_like(A1), A1_tilde]])\n",
    "        A_1 = np.block([[np.zeros_like(A2), A2], [A2_tilde, np.zeros_like(A2)]])\n",
    "        A_prime = A_0 + A_1\n",
    "        tensors_prime[mps.nodes[f\"site{i}\"].identifier] = A_prime\n",
    "\n",
    "    # Handle the last site\n",
    "    i = len(mps.nodes) - 1\n",
    "    C1 = mps.tensors[f\"site{i}\"][..., 0].reshape(mps.tensors[f\"site{i}\"][..., 0].shape[0], 1)\n",
    "    C1_tilde = mps_tilde.tensors[f\"site{i}\"][..., 0].reshape(mps_tilde.tensors[f\"site{i}\"][..., 0].shape[0], 1)\n",
    "    C2 = mps.tensors[f\"site{i}\"][..., 1].reshape(mps.tensors[f\"site{i}\"][..., 1].shape[0], 1)\n",
    "    C2_tilde = mps_tilde.tensors[f\"site{i}\"][..., 1].reshape(mps_tilde.tensors[f\"site{i}\"][..., 1].shape[0], 1)\n",
    "\n",
    "    tensors.append(C1 + C2)\n",
    "    tensors.append(C1_tilde + C2_tilde)\n",
    "\n",
    "    C_0 = np.block([[C1], [C1_tilde]])\n",
    "    C_1 = np.block([[C2], [C2_tilde]])\n",
    "    C_prime = C_0 + C_1\n",
    "    tensors_prime[mps.nodes[f\"site{i}\"].identifier] = C_prime\n",
    "\n",
    "    return tensors_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(433033.7280754056-2.1827872842550278e-11j)\n",
      "(1.0000000000000002+1.249000902703301e-16j)\n",
      "(1.0000000000000002+1.249000902703301e-16j)\n",
      "contraction befor normalization :  (6330.207954244057+1.1368683772161603e-13j)\n",
      "(6330.207954244057+1.1368683772161603e-13j)\n",
      "(1+0j)\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------##\n",
    "## Test the functions : normalize_ttn ##\n",
    "##------------------------------------##\n",
    "\n",
    "## MPS ##\n",
    "shapes = [(5, 2), (5, 7, 2), (7, 3, 2), (3, 6, 2), (6, 30, 2), (30, 2)]\n",
    "tensors1 = [ptn.crandn(shape) for shape in shapes]\n",
    "mps1 = ptn.MatrixProductState.from_tensor_list(tensors1,root_site=5,node_prefix=\"site\")\n",
    "\n",
    "print( ptn.contract_two_ttns(mps1,mps1.conjugate()))\n",
    "mps1_normalized = mps1.normalize_ttn(to_copy = False) # default is False\n",
    "print( ptn.contract_two_ttns(mps1,mps1.conjugate()))\n",
    "print(ptn.contract_two_ttns(mps1_normalized,mps1_normalized.conjugate()))\n",
    "\n",
    "## TTN ##\n",
    "ttn1 = ptn.random_big_ttns_two_root_children()\n",
    "\n",
    "print(\"contraction befor normalization : \" , ptn.contract_two_ttns(ttn1,ttn1.conjugate()))\n",
    "ttn1_normalized = ttn1.normalize_ttn(to_copy = True)\n",
    "print( ptn.contract_two_ttns(ttn1,ttn1.conjugate()))\n",
    "print( ptn.contract_two_ttns(ttn1_normalized,ttn1_normalized.conjugate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "(0.9999999999999998+0j)\n",
      "(1.0000000000000027-6.589788206355276e-18j)\n",
      "(0.9999999999999996-3.654108490508271e-18j)\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ttn1 = ptn.random_big_ttns_two_root_children()\n",
    "ttn2 = ptn.random_big_ttns_two_root_children()\n",
    "##---------------------##\n",
    "## Full density tensor ##\n",
    "##---------------------##\n",
    "\n",
    "## For pure states : (density tensor)^2 = density tensor \n",
    "pho , order = ttn1.density_tensor() \n",
    "# order = ['site0', 'site1', 'site2', 'site3', 'site4', 'site5', 'site6', 'site7']\n",
    "# density tensor * density tensor = density tensor :\n",
    "tensor = np.tensordot(pho,pho,axes=((8,9,10,11,12,13,14,15),(0,1,2,3,4,5,6,7)))\n",
    "print(np.allclose(tensor,pho))\n",
    "\n",
    "## trace of density tensor = 1\n",
    "def tensor_trace(pho):\n",
    "    \"\"\"\"\n",
    "    Args :\n",
    "        pho : Tensor\n",
    "    Returns :\n",
    "        trace : float\n",
    "    \"\"\"\n",
    "    for _ in range(pho.ndim//2):\n",
    "        pho = np.trace(pho, axis1 = 0, axis2 = pho.ndim//2)\n",
    "    return pho\n",
    "\n",
    "print(np.allclose(tensor_trace(pho),1))\n",
    "\n",
    "##---------------------------##\n",
    "## Full density tensor(ttno) ##\n",
    "##---------------------------##\n",
    "\n",
    "ttn = ptn.random_big_ttns_two_root_children()\n",
    "pho_ttno = ttn.density_ttno()\n",
    "\n",
    "## trace of density tensor = 1\n",
    "def ttno_trace(pho):\n",
    "    ttno_cct = deepcopy(pho)\n",
    "    ttno_cct = ttno_cct.completely_contract_tree()[0] \n",
    "    for _ in range(ttno_cct.ndim//2):\n",
    "        ttno_cct = np.trace(ttno_cct, axis1 = 0, axis2 = 1)\n",
    "    return ttno_cct\n",
    "\n",
    "print(np.allclose(ttno_trace(pho_ttno),1))\n",
    "\n",
    "## check density_ttno and density_tensor compatibility : \n",
    "ttn = ptn.random_small_ttns()\n",
    "pho , order = ttn.density_tensor() \n",
    "pho_ttno = ttn.density_ttno()\n",
    "np.allclose(pho_ttno.completely_contract_tree()[0],pho.transpose(0,3,1,4,2,5))\n",
    "\n",
    "##------------------------##\n",
    "## Reduced density tensor ##\n",
    "##------------------------##\n",
    "\n",
    "ttn = ptn.random_big_ttns_two_root_children()\n",
    "node_id = 'site0'\n",
    "# first method :\n",
    "pho_ref_1 = ttn.reduced_density_matrix_dict()[node_id]\n",
    "pho_ref_2 = ttn.reduced_density_matrix(node_id)\n",
    "# second method :\n",
    "pho = ttn.reduced_density_matrix_2(node_id)\n",
    "\n",
    "# trace of reduced density tensor = 1\n",
    "print(np.trace(pho, axis1 = 0, axis2 = 1))\n",
    "print(np.trace(pho_ref_1, axis1 = 0, axis2 = 1))\n",
    "print(np.trace(pho_ref_2, axis1 = 0, axis2 = 1))\n",
    "\n",
    "# Check Hermiticity : \n",
    "print(np.allclose(pho,pho.conjugate().T))\n",
    "print(np.allclose(pho_ref_1,pho_ref_1.conjugate().T))\n",
    "print(np.allclose(pho_ref_2,pho_ref_2.conjugate().T))\n",
    "\n",
    "# calculate explicitly the reduced density tensor of a node in a tree tensor network\n",
    "node_id = 'site4'\n",
    "ttn = ttn.normalize_ttn(to_copy=True)\n",
    "ttn.canonical_form(node_id , ptn.SVDParameters())\n",
    "C = ttn.tensors[node_id]\n",
    "reduced_density_matrix_dir = ptn.compute_transfer_tensor(C, tuple(range(C.ndim - 1)))\n",
    "\n",
    "\n",
    "reduced_density_matrix_ref_1 = ttn.reduced_density_matrix_dict()[node_id]\n",
    "reduced_density_matrix_ref_2 = ttn.reduced_density_matrix(node_id)\n",
    "\n",
    "print(np.allclose(reduced_density_matrix_dir,reduced_density_matrix_ref_1))\n",
    "print(np.allclose(reduced_density_matrix_dir,reduced_density_matrix_ref_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "First I did it with reduced_density_matrix_2, but I guess completely_contract_tree is more \n",
    "costly that moving the canoical center. I wonder why the results are\n",
    "not same!\n",
    "\"\"\"\n",
    "ttn = ptn.random_big_ttns_two_root_children()\n",
    "node_id = 'site2'\n",
    "pho = ttn.reduced_density_matrix_2(node_id)\n",
    "pho_tilde = ttn.reduced_density_matrix_dict()[node_id]\n",
    "print(np.allclose(pho,pho_tilde)) ######### Fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "##---------------------##\n",
    "## canonical_form :svd ##\n",
    "##---------------------##\n",
    "\n",
    "### MPS ###\n",
    "shapes = [(5, 2), (5, 7, 2), (7, 3, 2), (3, 6, 2), (6, 30, 2), (30, 2)]\n",
    "tensors1 = [ptn.crandn(shape) for shape in shapes]\n",
    "mps1 = ptn.MatrixProductState.from_tensor_list(tensors1,root_site=5,node_prefix=\"site\")\n",
    "\n",
    "## test canonical_form for \"site2\" :\n",
    "ref_contracted = ptn.contract_two_ttns(mps1,mps1.conjugate())\n",
    "mps1.canonical_form(\"site2\", ptn.SVDParameters())\n",
    "direct_contracted = ptn.compute_transfer_tensor(mps1.tensors[\"site2\"], tuple(range(mps1.tensors[\"site2\"].ndim )))\n",
    "print(np.allclose(ref_contracted, direct_contracted))\n",
    "\n",
    "### TTN ###\n",
    "ttn1 = ptn.random_big_ttns_two_root_children()\n",
    "\n",
    "# test canonical_form for \"site3\"\n",
    "direct_contracted = ptn.contract_two_ttns(ttn1,ttn1.conjugate())\n",
    "ttn1.canonical_form(\"site3\", ptn.SVDParameters())\n",
    "ref_contracted = ptn.compute_transfer_tensor(ttn1.tensors[\"site3\"], tuple(range(ttn1.tensors[\"site3\"].ndim )))\n",
    "print(np.allclose(ref_contracted, direct_contracted))\n",
    "\n",
    "\n",
    "# Check canonical_form with QR and SVD compatibility \n",
    "ttn = ptn.random_big_ttns_two_root_children()\n",
    "ttn1 = deepcopy(ttn)\n",
    "ttn1.canonical_form('site0', ptn.SVDParameters(max_bond_dim = np.inf, rel_tol= -np.inf, total_tol=-np.inf))\n",
    "ttn2 = deepcopy(ttn)\n",
    "ttn2.canonical_form('site0')\n",
    "a = ptn.compute_transfer_tensor(ttn1.tensors['site0'], (0,1,2))\n",
    "b = ptn.compute_transfer_tensor(ttn2.tensors['site0'], (0,1,2))\n",
    "c = ptn.contract_two_ttns(ttn,ttn.conjugate())\n",
    "print(np.allclose(a,b))\n",
    "print(np.allclose(a,c))\n",
    "print(np.allclose(b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "##-------------------------##\n",
    "## complete_canonical_form ##\n",
    "##-------------------------##\n",
    "\n",
    "# I defined new function because the canonical_form transforms ttns only to site cannonical form.\n",
    "#    - complete_canonical_form transforms all tensors to left Isometry \n",
    "#      with respect to root site controlled by SVD truncation parameters.\n",
    "\n",
    "### MPS ###\n",
    "shapes = [(5, 2), (5, 7, 2), (7, 3, 2), (3, 6, 2), (6, 30, 2), (30, 2)]\n",
    "tensors1 = [ptn.crandn(shape) for shape in shapes]\n",
    "mps1 = ptn.MatrixProductState.from_tensor_list(tensors1,root_site=5,node_prefix=\"site\")\n",
    "\n",
    "\n",
    "## test complete_canonical_form : \n",
    "mps1_norm = ptn.contract_two_ttns(mps1,mps1.conjugate())\n",
    "_ , norm = mps1.complete_canonical_form(ptn.SVDParameters())\n",
    "    # check the norm \n",
    "print(np.allclose(mps1_norm,norm))\n",
    "print(np.allclose(ptn.contract_two_ttns(mps1,mps1.conjugate()),1))\n",
    "    # check the orthogonality of root site = \"site5\"\n",
    "Identity = ptn.compute_transfer_tensor(mps1.tensors[mps1.root_id], (0,1) )\n",
    "print(np.allclose(Identity,1))\n",
    "    # check the orthogonality of \"site3\"\n",
    "Identity = ptn.compute_transfer_tensor(mps1.tensors[\"site3\"], (1,2) )\n",
    "print(np.allclose(Identity,np.eye(6)))\n",
    "    # check the orthogonality of leaf site = \"site0\"\n",
    "print(np.allclose(ptn.compute_transfer_tensor(mps1.tensors[\"site0\"], (1,) ),np.eye(2)))\n",
    "\n",
    "\n",
    "\n",
    "### TTN ###\n",
    "ttn1 = ptn.random_big_ttns_two_root_children()\n",
    "\n",
    "\n",
    "\n",
    "## test complete_canonical_form :\n",
    "ttn1_norm = ptn.contract_two_ttns(ttn1,ttn1.conjugate())\n",
    "_ , norm = ttn1.complete_canonical_form(ptn.SVDParameters())\n",
    "    # check the norm \n",
    "print(np.allclose(ttn1_norm,norm))\n",
    "print(np.allclose(ptn.contract_two_ttns(ttn1,ttn1.conjugate()),1)) \n",
    "    # check the orthogonality of root site = \"site0\"\n",
    "print(np.allclose(ptn.compute_transfer_tensor(ttn1.tensors[ttn1.root_id], (0,1,2) ),1))\n",
    "    # check the orthogonality of leaf site = \"site4\"\n",
    "print(np.allclose(ptn.compute_transfer_tensor(ttn1.tensors[\"site4\"], (1,) ),np.eye(2)))\n",
    "    # check the orthogonality of \"site3\"\n",
    "Identity = ptn.compute_transfer_tensor(ttn1.tensors[\"site3\"], (1,2,3) )\n",
    "print(np.allclose(Identity,np.eye(2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Krylov space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 84.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 117.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In first method, I applied one site projector at ecah step(along the same path as tdvp)\n",
    "\"\"\"\n",
    "# Initialize a random mps and ttn and their random hamiltonian : \n",
    "\n",
    "## MPS ##\n",
    "\"\"\"\n",
    "0 --- 1 --- 2 --- 3 --- 4 ---- 5\n",
    "|     |     |     |     |      |\n",
    "\n",
    "# order of legs =  [right_child, left_child, open_leg]\n",
    "\"\"\"\n",
    "shapes = [(5, 2), (5, 7, 2), (7, 3, 2), (3, 6, 2), (6, 30, 2), (30, 2)]\n",
    "tensors1 = [ptn.crandn(shape) for shape in shapes]\n",
    "mps1 = ptn.MatrixProductState.from_tensor_list(tensors1,root_site=5,node_prefix=\"site\")\n",
    "\n",
    "\"\"\"\n",
    "Question : \n",
    "tp = ptn.random_tensor_product(mps1, num_operators= len(mps1))\n",
    "H = ptn.Hamiltonian(tp)\n",
    "hamiltonian = ptn.TTNO.from_hamiltonian(H,mps1)\n",
    "this method no longer works (Error: state_diagram.obtain_tensor_shape)\n",
    "\"\"\"\n",
    "tensor = ptn.crandn([2,2,2,2,2,2,\n",
    "                     2,2,2,2,2,2])\n",
    "leg_dict = {\"site0\": 0, \"site1\": 1, \"site2\": 2, \"site3\": 3, \"site4\": 4, \"site5\": 5}\n",
    "ham_mps = ptn.TTNO.from_tensor(mps1, tensor, leg_dict)\n",
    "\n",
    "\n",
    "## start ##\n",
    "Krylov_space = ptn.Krylovz(mps1, ham_mps , 1, 10, ptn.TensorProduct({\"site0\": ptn.pauli_matrices()[0]}))\n",
    "results = Krylov_space.run(num_steps=4)\n",
    "print(results[0] == Krylov_space.initial_state)\n",
    "print(len(results) == 5)\n",
    "print(results[0] == Krylov_space.initial_state)\n",
    "# Krylov_space.results[1] = P*hamiltonian |inisial_state>\n",
    "# Krylov_space.results[2] = P*hamiltonian^2 |Krylov_space.results[1]>\n",
    "# Krylov_space.results[3] = P*hamiltonian^3 |Krylov_space.results[2]>\n",
    "# Krylov_space.results[4] = P*hamiltonian^4 |Krylov_space.results[3\n",
    "\n",
    "\n",
    "## TTN ##\n",
    "ttn1 = ptn.random_big_ttns_two_root_children()\n",
    "ham_ttn = ptn.TTNO.from_hamiltonian(ptn.random_hamiltonian_compatible(),ttn1)\n",
    "\n",
    "Krylov_space = ptn.Krylovz(ttn1, ham_ttn, 1,10,  ptn.TensorProduct({\"site0\": ptn.pauli_matrices()[0]}))\n",
    "results = Krylov_space.run(4 , ptn.SVDParameters())\n",
    "print(results[0] == Krylov_space.initial_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ortogonalize ttn against ttn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "I wanted to orthogonalize the outcome at each step to the previous states, but \n",
    "I could not find a way to ortogonilize two ttns against each other.\n",
    "I tried to orthogonalize each tensors seperately, but it did not work.\n",
    "\"\"\"\n",
    "\n",
    "def orthogonalize_against(ttn1 , ttn2):\n",
    "    \"\"\"\n",
    "    Orthogonalize all locale tensors of ttn1 against ttn2.\n",
    "    Args:\n",
    "        ttn1 : TreeTensorNetwork\n",
    "        ttn2 : TreeTensorNetwork\n",
    "    \"\"\"\n",
    "    for i in range(len(ttn1.nodes)):\n",
    "        shape = ttn1.tensors[f\"site{i}\"].shape\n",
    "        a = ttn1.tensors[f\"site{i}\"].reshape(-1)\n",
    "        b = deepcopy(ttn2.tensors[f\"site{i}\"])\n",
    "        b = normalize_tensor(b)\n",
    "        b = b.reshape(-1)\n",
    "        prod = np.tensordot(b.conj(), a , axes = (0,0) )\n",
    "        a = a - b * prod\n",
    "        a = a / np.sqrt(ptn.contract_two_ttns(ttn1,ttn1.conjugate()))\n",
    "        ttn1.tensors[f\"site{i}\"] = np.reshape(a,shape)\n",
    "    return ttn1 , ttn2\n",
    "\n",
    "def normalize_tensor(tensor): \n",
    "    \"\"\"\n",
    "     Normalize a tensor.\n",
    "     Args:\n",
    "          tensor : np.ndarray\n",
    "     Returns : \n",
    "          The normalized tensor.\n",
    "     \"\"\"\n",
    "    indices  = range(tensor.ndim)\n",
    "    norm = np.sqrt(np.tensordot(tensor,tensor.conj(), axes = (indices , indices) ))\n",
    "    return tensor / norm\n",
    "  \n",
    "## Test : (fails)\n",
    "shapes = [(5, 2), (5, 7, 2), (7, 3, 2), (3, 6, 2), (6, 30, 2), (30, 2)]\n",
    "tensors1 = [ptn.crandn(shape) for shape in shapes]\n",
    "tensors2 = [ptn.crandn(shape) for shape in shapes]\n",
    "mps1 = ptn.MatrixProductState.from_tensor_list(tensors1,root_site=5,node_prefix=\"site\")\n",
    "mps2 = ptn.MatrixProductState.from_tensor_list(tensors2,root_site=5,node_prefix=\"site\")\n",
    "orthogonalize_against(mps1,mps2)\n",
    "\n",
    "a = mps1.tensors[\"site2\"]\n",
    "b = mps2.tensors[\"site2\"]\n",
    "print(np.allclose(np.tensordot(b.conj(), a , axes = ((0,1,2),(0,1,2))), 0))\n",
    "print(np.allclose(ptn.contract_two_ttns(mps1,mps2.conjugate()),0)) # not orthogonal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Krylov_second_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this method, I contracted hamiltonian(TTNO) to the state(TTN) at each site. \\nthe bond dimension was growing exponentially, so at each step I transformed\\nthe state to the complete canonical form, where bond dimension are controlled by\\nSVD truncation parameters.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this method, I contracted hamiltonian(TTNO) to the state(TTN) at each site. \n",
    "the bond dimension was growing exponentially, so at each step I transformed\n",
    "the state to the complete canonical form, where bond dimension are controlled by\n",
    "SVD truncation parameters.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize mps : mps1\n",
    "\n",
    "# Antiferromagnet state\n",
    "mps_up = ptn.MatrixProductState.constant_product_state(state_value = 0,\n",
    "                                                     dimension =  2,\n",
    "                                                     num_sites = 15,\n",
    "                                                     node_prefix = \"site\", # default \n",
    "                                                     root_site = 14)\n",
    "\n",
    "mps_down = ptn.MatrixProductState.constant_product_state(state_value = 1,\n",
    "                                                     dimension =  2,\n",
    "                                                     num_sites = 15,\n",
    "                                                     node_prefix = \"site\", # default \n",
    "                                                     root_site = 14)    \n",
    "mps1 = deepcopy(mps_up)\n",
    "for i in range(len(mps1.nodes)):\n",
    "    if i % 2 == 0:\n",
    "       mps1.tensors[f\"site{i}\"] = mps_up.tensors[f\"site{i}\"]\n",
    "    else:\n",
    "       mps1.tensors[f\"site{i}\"] = mps_down.tensors[f\"site{i}\"]  \n",
    "\n",
    "\n",
    "# Initialize a random hamiltonian(TTNO) : mpo1\n",
    "\n",
    "X , Y , Z = ptn.pauli_matrices()\n",
    "possible_operators = [X, X@Y, Z@X, Z, Y, X@Y , Z@Z, Y@X, Z@Y ] \n",
    "sites = [f\"site{i}\" for i in range(len(mps1.nodes))]\n",
    "# List = ptn.random_symbolic_terms(num_of_terms=4, \n",
    "#                                 possible_operators=possible_operators, \n",
    "#                                 sites=sites, \n",
    "#                                 min_num_sites=2, \n",
    "#                                 max_num_sites=4, \n",
    "#                                 seed=None) ----> Error \n",
    "###########################################################\n",
    "List = ptn.random_terms(num_of_terms = 5,\n",
    "                        possible_operators = possible_operators,\n",
    "                        sites = sites,\n",
    "                        min_strength = 1,\n",
    "                        max_strength = 4,\n",
    "                        min_num_sites= 10,\n",
    "                        max_num_sites= 14)\n",
    "tp_list = [ptn.TensorProduct(term) for term in List]\n",
    "\n",
    "H = ptn.Hamiltonian(tp_list)\n",
    "H = H.pad_with_identities(mps1)\n",
    "# ttno1 = ptn.TTNO.from_hamiltonian(H, mps1) ----> Error: StateDiagram.from_hamiltonian\n",
    "##############################################################\n",
    "tp1 = ptn.random_tensor_product(mps1, num_operators= len(mps1), possible_operators = possible_operators)\n",
    "tp2 = ptn.random_tensor_product(mps1, num_operators= len(mps1), possible_operators = possible_operators)\n",
    "\n",
    "H = ptn.Hamiltonian([tp1,tp2])\n",
    "H = H.pad_with_identities(mps1)\n",
    "# mpo1 = ptn.TTNO.from_hamiltonian(H,mps1) ----> Error: StateDiagram.from_hamiltonian\n",
    "######################################################################################################\n",
    "\n",
    "conversion_dictionary = {}\n",
    "for i in range(len(mps1.nodes)):\n",
    "    conversion_dictionary[f\"{i}\"] = ptn.random_hermitian_matrix(2)\n",
    "for i in range(len(mps1.nodes)):\n",
    "    conversion_dictionary[f\"I{i}\"] = np.eye(i)\n",
    "\n",
    "dict = {}\n",
    "for i in range(len(mps1.nodes)):\n",
    "    dict[f\"site{i}\"] = f\"{i}\"\n",
    "tp1 = ptn.TensorProduct(dict)\n",
    "\n",
    "for i in range(len(mps1.nodes)):\n",
    "    dict[f\"site{i}\"] = f\"{len(mps1.nodes) - i-1}\"\n",
    "tp2 = ptn.TensorProduct(dict)\n",
    "\n",
    "H = ptn.Hamiltonian([tp1,tp2],conversion_dictionary)\n",
    "H = H.pad_with_identities(mps1)\n",
    "mpo1 = ptn.TTNO.from_hamiltonian(H,mps1) # All bond dimnsions are 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(1.000000000000001+8.326672684688674e-17j)\n",
      "(0.9999999999999989-1.1102230246251565e-16j)\n",
      "(1.0000000000000038-1.3877787807814457e-16j)\n",
      "True\n",
      "(1, 1, 2)\n",
      "(4, 4, 2)\n",
      "(10, 12, 2)\n",
      "(31, 36, 2)\n",
      "(81, 91, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Krylov_space = ptn.Krylov_second_method(mps1, mpo1)\n",
    "Krylov_space.run(10, ptn.SVDParameters())\n",
    "results = Krylov_space.results\n",
    "\n",
    "\n",
    "# results[0] = initial_state\n",
    "print(results[0] == mps1)\n",
    "# results[1] = hamiltonian |inisial_state>\n",
    "# results[2] = hamiltonian^2 |Krylov_space.results[1]>\n",
    "# results[3] = hamiltonian^3 |Krylov_space.results[2]>\n",
    "# results[4] = hamiltonian^4 |Krylov_space.results[3]>\n",
    "# Check the norms \n",
    "print(ptn.contract_two_ttns(results[1],results[1].conjugate()))\n",
    "print(ptn.contract_two_ttns(results[5],results[5].conjugate()))\n",
    "print(ptn.contract_two_ttns(results[10],results[10].conjugate()))\n",
    "# check the orthogonality of root site = \"site14\"\n",
    "print(np.allclose(ptn.compute_transfer_tensor( results[2].tensors[ttn1.root_id], (0,)) , np.eye(2) ))\n",
    "# the growth of bind dimensions at \"site10\"\n",
    "print(results[0].tensors[\"site10\"].shape)\n",
    "print(results[2].tensors[\"site10\"].shape)\n",
    "print(results[4].tensors[\"site10\"].shape)\n",
    "print(results[6].tensors[\"site10\"].shape)\n",
    "print(results[8].tensors[\"site10\"].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
