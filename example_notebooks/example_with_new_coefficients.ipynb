{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pytreenet as ptn\n",
    "import random\n",
    "from numpy.random import default_rng, Generator\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Tensor Network Operator for the Toy Model\n",
    "In the main manuscript we consider a toy Hamiltonian to show the workings of our algorithm to find tree tensor network operators from a Hamiltonian. The toy Hamiltonian is defined on a tree structure as given in Fig.4.1a) in the main manuscript as\n",
    "$$\n",
    "H_{\\text{toy}}= \\sum_{j=1}^4 h_j = Y_2 X_3 X_4 + X_1 Y_2 Y_6 + X_1 Y_2 Z_5 + Z_5 X_7 X_8.\n",
    "$$\n",
    "Here we want to show that our implemented algorithm yields the same state diagrams as the ones shown in the main text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the tree\n",
    "def construct_reference_tree() -> ptn.TreeTensorNetworkState:\n",
    "    \"\"\"\n",
    "    Generates the desired tree tensor network used as a reference to construct\n",
    "     the Hamiltonian.\n",
    "    \"\"\"\n",
    "    ttns = ptn.TreeTensorNetworkState()\n",
    "    # Physical legs come last\n",
    "    node1, tensor1 = ptn.random_tensor_node((1, 1, 2), identifier=\"site1\")\n",
    "    node2, tensor2 = ptn.random_tensor_node((1, 1, 1, 2), identifier=\"site2\")\n",
    "    node3, tensor3 = ptn.random_tensor_node((1, 2), identifier=\"site3\")\n",
    "    node4, tensor4 = ptn.random_tensor_node((1, 2), identifier=\"site4\")\n",
    "    node5, tensor5 = ptn.random_tensor_node((1, 1, 1, 2), identifier=\"site5\")\n",
    "    node6, tensor6 = ptn.random_tensor_node((1, 2), identifier=\"site6\")\n",
    "    node7, tensor7 = ptn.random_tensor_node((1, 1, 2), identifier=\"site7\")\n",
    "    node8, tensor8 = ptn.random_tensor_node((1, 2), identifier=\"site8\")\n",
    "    \n",
    "    ttns.add_root(node1, tensor1)\n",
    "    ttns.add_child_to_parent(node2, tensor2, 0, \"site1\", 0)\n",
    "    ttns.add_child_to_parent(node3, tensor3, 0, \"site2\", 1)\n",
    "    ttns.add_child_to_parent(node4, tensor4, 0, \"site2\", 2)\n",
    "    ttns.add_child_to_parent(node5, tensor5, 0, \"site1\", 1)\n",
    "    ttns.add_child_to_parent(node6, tensor6, 0, \"site5\", 1)\n",
    "    ttns.add_child_to_parent(node7, tensor7, 0, \"site5\", 2)\n",
    "    ttns.add_child_to_parent(node8, tensor8, 0, \"site7\", 1)\n",
    "    return ttns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_toy_hamiltonian() -> ptn.Hamiltonian:\n",
    "    paulis = ptn.pauli_matrices()\n",
    "    conversion_dict = {\"X\": paulis[0], \"Y\": paulis[1], \"Z\": paulis[2], \"I2\": np.eye(2)}\n",
    "    \n",
    "    ham = [{'site8': 'I2', 'site4': 'Z', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site5': 'I2', 'site6': 'I2', 'site7': 'I2'}, {'site4': 'I2', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site5': 'I2', 'site6': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site5': 'I2', 'site8': 'Z', 'site1': 'X', 'site2': 'I2', 'site3': 'I2', 'site4': 'I2', 'site6': 'I2', 'site7': 'I2'}, {'site5': 'X', 'site4': 'Z', 'site6': 'Y', 'site7': 'Y', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site8': 'I2'}]\n",
    "    #coeffs = [1, 1, 1, 1]\n",
    "    \n",
    "    return ptn.Hamiltonian([ptn.TensorProduct(i) for i in ham], conversion_dictionary=conversion_dict) #, coeffs = [random.randint(1, 100) for _ in range(18)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_hamiltonian(ham, coeffs_mapping, coeffs= None, ) -> ptn.Hamiltonian:\n",
    "\n",
    "    if coeffs is None:\n",
    "        coeffs = [1 for _ in range(len(ham))]\n",
    "    \n",
    "    paulis = ptn.pauli_matrices()\n",
    "    conversion_dict = {\"X\": paulis[0], \"Y\": paulis[1], \"Z\": paulis[2], \"I2\": np.eye(2)}\n",
    "    return ptn.Hamiltonian([ptn.TensorProduct(i) for i in ham], conversion_dictionary=conversion_dict, coeffs=coeffs, coeffs_mapping=coeffs_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_toy_hamiltonian() -> ptn.Hamiltonian:\n",
    "    paulis = ptn.pauli_matrices()\n",
    "    conversion_dict = {\"X\": paulis[0], \"Y\": paulis[1], \"Z\": paulis[2], \"I2\": np.eye(2)}\n",
    "    term1 = ptn.TensorProduct({\"site2\": \"Y\", \"site3\": \"X\", \"site4\": \"X\"})\n",
    "    term2 = ptn.TensorProduct({\"site1\": \"X\", \"site2\": \"Y\", \"site6\": \"Y\"})\n",
    "    term3 = ptn.TensorProduct({\"site1\": \"X\", \"site2\": \"Y\", \"site5\": \"Z\"})\n",
    "    term4 = ptn.TensorProduct({\"site5\": \"Z\", \"site7\": \"X\", \"site3\": \"X\"})\n",
    "    terms = [term1, term2, term3, term4]\n",
    "    coeffs = [(Fraction(2,3),\"2\"), (Fraction(1,4),\"3\"), (Fraction(1,3),\"4\"), (Fraction(1,2),\"5\")]\n",
    "    ham_terms =  [(x, y, z) for (x, y), z in zip(coeffs, terms)]\n",
    "    coeffs_mapping = {\"1\":1, \"2\":2, \"3\":3, \"4\":4, \"5\":5}\n",
    "    \n",
    "    return ptn.Hamiltonian(ham_terms, conversion_dictionary=conversion_dict ,coeffs_mapping=coeffs_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hamiltonian_toy = construct_hamiltonian(ham, ham_dict, coeffs)\n",
    "hamiltonian_toy = construct_toy_hamiltonian()\n",
    "ttns_root1 = construct_reference_tree()\n",
    "hamiltonian1 = hamiltonian_toy.pad_with_identities(ttns_root1)\n",
    "#hamiltonian1 = hamiltonian_toy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Single Term Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Diagram for term 0\n",
      "Hyperedges: {'site1': 'I2 (2/3 * 2)', 'site2': 'Y (1 * 1)', 'site3': 'X (1 * 1)', 'site4': 'X (1 * 1)', 'site5': 'I2 (1 * 1)', 'site6': 'I2 (1 * 1)', 'site7': 'I2 (1 * 1)', 'site8': 'I2 (1 * 1)'}\n",
      "Vertices: [('site1', 'site2'), ('site1', 'site5'), ('site2', 'site3'), ('site2', 'site4'), ('site5', 'site6'), ('site5', 'site7'), ('site7', 'site8')]\n",
      "-----------------\n",
      "State Diagram for term 1\n",
      "Hyperedges: {'site1': 'X (1/4 * 3)', 'site2': 'Y (1 * 1)', 'site3': 'I2 (1 * 1)', 'site4': 'I2 (1 * 1)', 'site5': 'I2 (1 * 1)', 'site6': 'Y (1 * 1)', 'site7': 'I2 (1 * 1)', 'site8': 'I2 (1 * 1)'}\n",
      "Vertices: [('site1', 'site2'), ('site1', 'site5'), ('site2', 'site3'), ('site2', 'site4'), ('site5', 'site6'), ('site5', 'site7'), ('site7', 'site8')]\n",
      "-----------------\n",
      "State Diagram for term 2\n",
      "Hyperedges: {'site1': 'X (1/3 * 4)', 'site2': 'Y (1 * 1)', 'site3': 'I2 (1 * 1)', 'site4': 'I2 (1 * 1)', 'site5': 'Z (1 * 1)', 'site6': 'I2 (1 * 1)', 'site7': 'I2 (1 * 1)', 'site8': 'I2 (1 * 1)'}\n",
      "Vertices: [('site1', 'site2'), ('site1', 'site5'), ('site2', 'site3'), ('site2', 'site4'), ('site5', 'site6'), ('site5', 'site7'), ('site7', 'site8')]\n",
      "-----------------\n",
      "State Diagram for term 3\n",
      "Hyperedges: {'site1': 'I2 (1/2 * 5)', 'site2': 'I2 (1 * 1)', 'site3': 'X (1 * 1)', 'site4': 'I2 (1 * 1)', 'site5': 'Z (1 * 1)', 'site6': 'I2 (1 * 1)', 'site7': 'X (1 * 1)', 'site8': 'I2 (1 * 1)'}\n",
      "Vertices: [('site1', 'site2'), ('site1', 'site5'), ('site2', 'site3'), ('site2', 'site4'), ('site5', 'site6'), ('site5', 'site7'), ('site7', 'site8')]\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for i, term in enumerate(hamiltonian1.terms):\n",
    "    single_term_diag = ptn.SingleTermDiagram.from_single_term(term, ttns_root1)\n",
    "    print(f\"State Diagram for term {i}\")\n",
    "    print(single_term_diag)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the single term diagrams are exactly the one we depicted in Fig. 4.1b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete State Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "hyperedges:\n",
      "label = I2; corr_site = site1; coeff = 2/3 * 2; connected to ('site1', 'site2'), ('site1', 'site5'), \n",
      "label = X; corr_site = site1; coeff = 1 * 1; connected to ('site1', 'site2'), ('site1', 'site5'), \n",
      "label = I2; corr_site = site1; coeff = 1/2 * 5; connected to ('site1', 'site2'), ('site1', 'site5'), \n",
      "label = Y; corr_site = site2; coeff = 1 * 1; connected to ('site1', 'site2'), ('site2', 'site3'), ('site2', 'site4'), \n",
      "label = Y; corr_site = site2; coeff = 1 * 1; connected to ('site1', 'site2'), ('site2', 'site3'), ('site2', 'site4'), \n",
      "label = I2; corr_site = site2; coeff = 1 * 1; connected to ('site1', 'site2'), ('site2', 'site3'), ('site2', 'site4'), \n",
      "label = X; corr_site = site3; coeff = 1 * 1; connected to ('site2', 'site3'), \n",
      "label = I2; corr_site = site3; coeff = 1 * 1; connected to ('site2', 'site3'), \n",
      "label = X; corr_site = site4; coeff = 1 * 1; connected to ('site2', 'site4'), \n",
      "label = I2; corr_site = site4; coeff = 1 * 1; connected to ('site2', 'site4'), \n",
      "label = I2; corr_site = site5; coeff = 1 * 1; connected to ('site1', 'site5'), ('site5', 'site6'), ('site5', 'site7'), \n",
      "label = I2; corr_site = site5; coeff = 1/4 * 3; connected to ('site1', 'site5'), ('site5', 'site6'), ('site5', 'site7'), \n",
      "label = Z; corr_site = site5; coeff = 1/3 * 4; connected to ('site1', 'site5'), ('site5', 'site6'), ('site5', 'site7'), \n",
      "label = Z; corr_site = site5; coeff = 1 * 1; connected to ('site1', 'site5'), ('site5', 'site6'), ('site5', 'site7'), \n",
      "label = I2; corr_site = site6; coeff = 1 * 1; connected to ('site5', 'site6'), \n",
      "label = Y; corr_site = site6; coeff = 1 * 1; connected to ('site5', 'site6'), \n",
      "label = I2; corr_site = site7; coeff = 1 * 1; connected to ('site5', 'site7'), ('site7', 'site8'), \n",
      "label = X; corr_site = site7; coeff = 1 * 1; connected to ('site5', 'site7'), ('site7', 'site8'), \n",
      "label = I2; corr_site = site8; coeff = 1 * 1; connected to ('site7', 'site8'), \n",
      "\n",
      " vertices:\n",
      "corr_edge = ('site1', 'site2'); connected to (Y, site2, 96215baa-d472-11ef-930e-76b9c323d81b), (I2, site1, 96215998-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site1', 'site2'); connected to (Y, site2, 962163b6-d472-11ef-930e-76b9c323d81b), (X, site1, 962162a8-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site1', 'site2'); connected to (I2, site2, 96217b44-d472-11ef-930e-76b9c323d81b), (I2, site1, 96217a40-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site1', 'site5'); connected to (I2, site5, 96215d80-d472-11ef-930e-76b9c323d81b), (I2, site1, 96215998-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site1', 'site5'); connected to (Z, site5, 96217cfc-d472-11ef-930e-76b9c323d81b), (I2, site1, 96217a40-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site1', 'site5'); connected to (I2, site5, 96216564-d472-11ef-930e-76b9c323d81b), (X, site1, 962162a8-d472-11ef-930e-76b9c323d81b), (Z, site5, 96217608-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site2', 'site3'); connected to (X, site3, 96215cae-d472-11ef-930e-76b9c323d81b), (Y, site2, 96215baa-d472-11ef-930e-76b9c323d81b), (I2, site2, 96217b44-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site2', 'site3'); connected to (I2, site3, 9621649c-d472-11ef-930e-76b9c323d81b), (Y, site2, 962163b6-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site2', 'site4'); connected to (X, site4, 96215d1c-d472-11ef-930e-76b9c323d81b), (Y, site2, 96215baa-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site2', 'site4'); connected to (I2, site4, 96216500-d472-11ef-930e-76b9c323d81b), (Y, site2, 962163b6-d472-11ef-930e-76b9c323d81b), (I2, site2, 96217b44-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site5', 'site6'); connected to (I2, site6, 96215e7a-d472-11ef-930e-76b9c323d81b), (I2, site5, 96215d80-d472-11ef-930e-76b9c323d81b), (Z, site5, 96217608-d472-11ef-930e-76b9c323d81b), (Z, site5, 96217cfc-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site5', 'site6'); connected to (Y, site6, 96216654-d472-11ef-930e-76b9c323d81b), (I2, site5, 96216564-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site5', 'site7'); connected to (I2, site7, 96215ee8-d472-11ef-930e-76b9c323d81b), (I2, site5, 96215d80-d472-11ef-930e-76b9c323d81b), (I2, site5, 96216564-d472-11ef-930e-76b9c323d81b), (Z, site5, 96217608-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site5', 'site7'); connected to (X, site7, 96217e5a-d472-11ef-930e-76b9c323d81b), (Z, site5, 96217cfc-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site7', 'site8'); connected to (I2, site8, 96215f92-d472-11ef-930e-76b9c323d81b), (I2, site7, 96215ee8-d472-11ef-930e-76b9c323d81b), (X, site7, 96217e5a-d472-11ef-930e-76b9c323d81b), \n",
      "\n",
      "{'1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n"
     ]
    }
   ],
   "source": [
    "state_diagram1 = ptn.StateDiagram.from_hamiltonian(hamiltonian1, ttns_root1, ptn.state_diagram.TTNOFinder.SGE)\n",
    "print(len(state_diagram1.get_all_vertices()))\n",
    "print(state_diagram1)\n",
    "#ptn.TTNO.from_hamiltonian(hamiltonian1, ttns_root1)\n",
    "#print(state_diagram1.coeffs, state_diagram1.coeffs_indices)\n",
    "print(hamiltonian1.coeffs_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "hyperedges:\n",
      "label = I2; corr_site = site1; coeff = 2/3 * 2; connected to ('site1', 'site2'), ('site1', 'site5'), \n",
      "label = X; corr_site = site1; coeff = 1/4 * 3; connected to ('site1', 'site2'), ('site1', 'site5'), \n",
      "label = I2; corr_site = site1; coeff = 1/2 * 5; connected to ('site1', 'site2'), ('site1', 'site5'), \n",
      "label = Y; corr_site = site2; coeff = 1 * 1; connected to ('site1', 'site2'), ('site2', 'site3'), ('site2', 'site4'), \n",
      "label = Y; corr_site = site2; coeff = 1 * 1; connected to ('site1', 'site2'), ('site2', 'site3'), ('site2', 'site4'), \n",
      "label = I2; corr_site = site2; coeff = 1 * 1; connected to ('site1', 'site2'), ('site2', 'site3'), ('site2', 'site4'), \n",
      "label = X; corr_site = site3; coeff = 1 * 1; connected to ('site2', 'site3'), \n",
      "label = I2; corr_site = site3; coeff = 1 * 1; connected to ('site2', 'site3'), \n",
      "label = X; corr_site = site4; coeff = 1 * 1; connected to ('site2', 'site4'), \n",
      "label = I2; corr_site = site4; coeff = 1 * 1; connected to ('site2', 'site4'), \n",
      "label = I2; corr_site = site5; coeff = 1 * 1; connected to ('site1', 'site5'), ('site5', 'site6'), ('site5', 'site7'), \n",
      "label = I2; corr_site = site5; coeff = 1 * 1; connected to ('site1', 'site5'), ('site5', 'site6'), ('site5', 'site7'), \n",
      "label = Z; corr_site = site5; coeff = 1 * 1; connected to ('site1', 'site5'), ('site5', 'site6'), ('site5', 'site7'), \n",
      "label = Z; corr_site = site5; coeff = 1 * 1; connected to ('site1', 'site5'), ('site5', 'site6'), ('site5', 'site7'), \n",
      "label = I2; corr_site = site6; coeff = 1 * 1; connected to ('site5', 'site6'), \n",
      "label = Y; corr_site = site6; coeff = 1 * 1; connected to ('site5', 'site6'), \n",
      "label = I2; corr_site = site7; coeff = 1 * 1; connected to ('site5', 'site7'), ('site7', 'site8'), \n",
      "label = X; corr_site = site7; coeff = 1 * 1; connected to ('site5', 'site7'), ('site7', 'site8'), \n",
      "label = I2; corr_site = site8; coeff = 1 * 1; connected to ('site7', 'site8'), \n",
      "\n",
      " vertices:\n",
      "corr_edge = ('site1', 'site2'); connected to (I2, site1, 99cfe0e6-d472-11ef-930e-76b9c323d81b), (Y, site2, 99cfe316-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site1', 'site2'); connected to (X, site1, 99cff2e8-d472-11ef-930e-76b9c323d81b), (Y, site2, 99cff4aa-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site1', 'site2'); connected to (I2, site1, 99d00c2e-d472-11ef-930e-76b9c323d81b), (I2, site2, 99d00ce2-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site1', 'site5'); connected to (I2, site1, 99cfe0e6-d472-11ef-930e-76b9c323d81b), (I2, site5, 99cfe51e-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site1', 'site5'); connected to (X, site1, 99cff2e8-d472-11ef-930e-76b9c323d81b), (I2, site5, 99cff70c-d472-11ef-930e-76b9c323d81b), (Z, site5, 99d0030a-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site1', 'site5'); connected to (I2, site1, 99d00c2e-d472-11ef-930e-76b9c323d81b), (Z, site5, 99d00e22-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site2', 'site3'); connected to (Y, site2, 99cfe316-d472-11ef-930e-76b9c323d81b), (X, site3, 99cfe438-d472-11ef-930e-76b9c323d81b), (I2, site2, 99d00ce2-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site2', 'site3'); connected to (Y, site2, 99cff4aa-d472-11ef-930e-76b9c323d81b), (I2, site3, 99cff568-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site2', 'site4'); connected to (Y, site2, 99cfe316-d472-11ef-930e-76b9c323d81b), (X, site4, 99cfe4a6-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site2', 'site4'); connected to (Y, site2, 99cff4aa-d472-11ef-930e-76b9c323d81b), (I2, site4, 99cff608-d472-11ef-930e-76b9c323d81b), (I2, site2, 99d00ce2-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site5', 'site6'); connected to (I2, site5, 99cfe51e-d472-11ef-930e-76b9c323d81b), (I2, site6, 99cfe640-d472-11ef-930e-76b9c323d81b), (Z, site5, 99d0030a-d472-11ef-930e-76b9c323d81b), (Z, site5, 99d00e22-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site5', 'site6'); connected to (I2, site5, 99cff70c-d472-11ef-930e-76b9c323d81b), (Y, site6, 99cff7a2-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site5', 'site7'); connected to (I2, site5, 99cfe51e-d472-11ef-930e-76b9c323d81b), (I2, site7, 99cfe6b8-d472-11ef-930e-76b9c323d81b), (I2, site5, 99cff70c-d472-11ef-930e-76b9c323d81b), (Z, site5, 99d0030a-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site5', 'site7'); connected to (Z, site5, 99d00e22-d472-11ef-930e-76b9c323d81b), (X, site7, 99d00eea-d472-11ef-930e-76b9c323d81b), \n",
      "corr_edge = ('site7', 'site8'); connected to (I2, site7, 99cfe6b8-d472-11ef-930e-76b9c323d81b), (I2, site8, 99cfe776-d472-11ef-930e-76b9c323d81b), (X, site7, 99d00eea-d472-11ef-930e-76b9c323d81b), \n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_diagram2 = ptn.StateDiagram.from_hamiltonian(hamiltonian1, ttns_root1, ptn.TTNOFinder.TREE)\n",
    "print(len(state_diagram2.get_all_vertices()))\n",
    "print(state_diagram2)\n",
    "#ptn.TTNO.from_hamiltonian(hamiltonian1, ttns_root1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare tensor values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_permutation_rec(ttno, leg_dict, node_id, perm):\n",
    "    node, _ = ttno[node_id]\n",
    "    input_index = leg_dict[node_id]\n",
    "    output_index = input_index + len(ttno.nodes)\n",
    "    perm.extend([output_index, input_index ])\n",
    "    if not node.is_leaf():\n",
    "        for child_id in node.children:\n",
    "            _find_permutation_rec(ttno, leg_dict, child_id, perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equality:  True\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "leg_dict = {\"site1\": 0, \"site2\": 1, \"site3\": 2, \"site4\": 3, \"site5\": 4,\n",
    "                \"site6\": 5, \"site7\": 6, \"site8\": 7}\n",
    "\n",
    "original_tensor = hamiltonian1.to_tensor(ttns_root1).operator#.transpose([3,0,4,1,5,2])\n",
    "\n",
    "ttno = ptn.TTNO.from_hamiltonian(hamiltonian1, ttns_root1, ptn.state_diagram.TTNOFinder.BASE)\n",
    "\n",
    "\n",
    "#print(ttno.tensors)\n",
    "\n",
    "contructed_tensor = ttno.completely_contract_tree(to_copy=True)[0]\n",
    "\n",
    "permutation = []\n",
    "_find_permutation_rec(ttno, leg_dict, ttno.root_id, permutation)\n",
    "correct_tensor = original_tensor.transpose(permutation)\n",
    "#print(permutation)\n",
    "\n",
    "\n",
    "print(\"Equality: \", np.allclose(correct_tensor,contructed_tensor))\n",
    "#print(original_tensor)\n",
    "print(\"---------------------------\")\n",
    "#print(contructed_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that this state diagram corresponds to the state diagram given in Fig. 4.1c) in the main text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_bond_dimensions(ttno: ptn.TTNO) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Obtains the bond dimensions of a TTN.\n",
    "\n",
    "    Args:\n",
    "        ttno (ptn.TTNO): The TTN for which to determine the bond dimensions.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 1D-array containing all bond-dimensions\n",
    "    \"\"\"\n",
    "    dimensions = []\n",
    "    for node_id in ttno.nodes:\n",
    "        node = ttno.nodes[node_id]\n",
    "        if not node.is_root():\n",
    "            dimensions.append(node.parent_leg_dim())\n",
    "    return np.asarray(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham_dim [1 1 1 1 1 1 1] svd_dim [1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "leg_dict = {\"site1\": 0, \"site2\": 1, \"site3\": 2, \"site4\": 3, \"site5\": 4,\n",
    "                \"site6\": 5, \"site7\": 6, \"site8\": 7,\"site9\": 8}\n",
    "ttno_ham = ptn.TTNO.from_hamiltonian(hamiltonian1, ttns_root1)\n",
    "total_tensor = hamiltonian1.to_tensor(ttns_root1).operator\n",
    "ttno_svd = ptn.TTNO.from_tensor(ttns_root1,\n",
    "                                total_tensor,\n",
    "                                leg_dict,\n",
    "                                mode=ptn.Decomposition.tSVD)\n",
    "ham_dim = obtain_bond_dimensions(ttno_ham)\n",
    "svd_dim = obtain_bond_dimensions(ttno_svd)\n",
    "\n",
    "print(\"ham_dim\",ham_dim,\"svd_dim\", svd_dim)\n",
    "if np.any(ham_dim > svd_dim):\n",
    "    print(ham_dim, svd_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Minimum problematic hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = [{'site4': 'Z', 'site2': 'Y', 'site8': 'Y', 'site1': 'I2', 'site3': 'I2', 'site5': 'I2', 'site6': 'I2', 'site7': 'I2'}, {'site5': 'Y', 'site1': 'Z', 'site3': 'X', 'site2': 'Z', 'site4': 'I2', 'site6': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site7': 'Z', 'site8': 'Y', 'site2': 'I2', 'site6': 'X', 'site5': 'I2', 'site1': 'I2', 'site3': 'I2', 'site4': 'I2'}, {'site3': 'I2', 'site4': 'Z', 'site7': 'X', 'site8': 'Z', 'site1': 'I2', 'site2': 'I2', 'site5': 'I2', 'site6': 'I2'}, {'site6': 'I2', 'site5': 'Y', 'site1': 'X', 'site8': 'X', 'site4': 'Z', 'site7': 'X', 'site2': 'I2', 'site3': 'I2'}, {'site6': 'I2', 'site1': 'Y', 'site5': 'Z', 'site4': 'I2', 'site2': 'I2', 'site3': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site3': 'I2', 'site4': 'X', 'site2': 'X', 'site1': 'X', 'site6': 'I2', 'site5': 'Z', 'site7': 'I2', 'site8': 'I2'}, {'site4': 'X', 'site2': 'Z', 'site1': 'I2', 'site3': 'I2', 'site5': 'I2', 'site6': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site5': 'I2', 'site7': 'I2', 'site2': 'Z', 'site4': 'X', 'site3': 'Y', 'site8': 'I2', 'site1': 'I2', 'site6': 'I2'}, {'site7': 'X', 'site4': 'Z', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site5': 'I2', 'site6': 'I2', 'site8': 'I2'}, {'site8': 'Z', 'site7': 'X', 'site2': 'I2', 'site1': 'I2', 'site3': 'I2', 'site4': 'I2', 'site5': 'I2', 'site6': 'I2'}, {'site2': 'I2', 'site6': 'Y', 'site8': 'Z', 'site1': 'Z', 'site3': 'Z', 'site4': 'I2', 'site5': 'I2', 'site7': 'I2'}, {'site8': 'I2', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site4': 'I2', 'site5': 'I2', 'site6': 'I2', 'site7': 'I2'}, {'site2': 'I2', 'site3': 'I2', 'site6': 'Z', 'site7': 'Z', 'site4': 'Z', 'site8': 'Z', 'site1': 'I2', 'site5': 'I2'}, {'site8': 'Y', 'site6': 'X', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site4': 'I2', 'site5': 'I2', 'site7': 'I2'}, {'site7': 'X', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site4': 'I2', 'site5': 'I2', 'site6': 'I2', 'site8': 'I2'}, {'site8': 'Y', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site4': 'I2', 'site5': 'I2', 'site6': 'I2', 'site7': 'I2'}, {'site8': 'I2', 'site3': 'X', 'site1': 'I2', 'site2': 'I2', 'site4': 'I2', 'site5': 'I2', 'site6': 'I2', 'site7': 'I2'}]\n",
    "coeffs = [-4.67, -2.9633104276996303, 6.680706729782859, -4.30560120789554, 5.202483584181863, 8.505121153194981, -4.011735853871354, -7.643281057886108, 6.157174317449904, 9.561269374270271, 2.9385071692017757, -8.54746490019713, 7.798682301513789, -4.6568899743444785, 9.241682837178718, -6.285495010325322, -5.907195938916027, -4.12665854873854]\n",
    "leg_dict = {\"site1\": 0, \"site2\": 1, \"site3\": 2, \"site4\": 3, \"site5\": 4, \"site6\": 5, \"site7\": 6, \"site8\": 7,\"site9\": 8}\n",
    "        \n",
    "for i in range(len(ham)):\n",
    "    c = coeffs[i]\n",
    "    coeffs[i] = coeffs[i]+10\n",
    "    hamiltonian_temp = construct_hamiltonian(ham,coeffs)\n",
    "    ttns_root = construct_reference_tree()\n",
    "    ham_t = hamiltonian_temp.pad_with_identities(ttns_root)\n",
    "\n",
    "    ttno_ham = ptn.TTNO.from_hamiltonian(ham_t, ttns_root)\n",
    "    total_tensor = ham_t.to_tensor(ttns_root).operator\n",
    "    ttno_svd = ptn.TTNO.from_tensor(ttns_root,\n",
    "                                    total_tensor,\n",
    "                                    leg_dict,\n",
    "                                    mode=ptn.Decomposition.tSVD)\n",
    "    ham_dim = obtain_bond_dimensions(ttno_ham)\n",
    "    svd_dim = obtain_bond_dimensions(ttno_svd)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    if np.any(ham_dim > svd_dim):\n",
    "        print(i, ham_dim, svd_dim, \"still broken for\")\n",
    "    coeffs[i] = c\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ham, coeffs = [{'site1': 'X', 'site8': 'Y', 'site2': 'I2', 'site3': 'I2', 'site4': 'I2', 'site5': 'I2', 'site6': 'I2', 'site7': 'I2'}, {'site3': 'Y', 'site8': 'I2', 'site1': 'I2', 'site2': 'I2', 'site4': 'I2', 'site5': 'I2', 'site6': 'I2', 'site7': 'I2'}, {'site8': 'I2', 'site7': 'Z', 'site2': 'X', 'site1': 'I2', 'site3': 'I2', 'site4': 'I2', 'site5': 'I2', 'site6': 'I2'}, {'site6': 'Z', 'site1': 'I2', 'site7': 'I2', 'site5': 'Z', 'site8': 'Y', 'site2': 'X', 'site3': 'I2', 'site4': 'I2'}, {'site6': 'Z', 'site1': 'I2', 'site8': 'X', 'site3': 'Z', 'site2': 'X', 'site7': 'X', 'site4': 'I2', 'site5': 'I2'}, {'site7': 'Z', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site4': 'I2', 'site5': 'I2', 'site6': 'I2', 'site8': 'I2'}, {'site3': 'Z', 'site5': 'X', 'site6': 'X', 'site2': 'Z', 'site8': 'I2', 'site1': 'I2', 'site4': 'I2', 'site7': 'I2'}, {'site4': 'Z', 'site8': 'X', 'site5': 'I2', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site6': 'I2', 'site7': 'I2'}, {'site3': 'X', 'site1': 'I2', 'site2': 'I2', 'site4': 'I2', 'site5': 'I2', 'site6': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site4': 'Z', 'site7': 'Z', 'site6': 'Y', 'site3': 'I2', 'site1': 'I2', 'site8': 'X', 'site2': 'I2', 'site5': 'I2'}, {'site5': 'Z', 'site8': 'I2', 'site2': 'I2', 'site4': 'I2', 'site1': 'I2', 'site3': 'I2', 'site6': 'I2', 'site7': 'I2'}, {'site5': 'Z', 'site3': 'Z', 'site2': 'I2', 'site1': 'I2', 'site4': 'I2', 'site6': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site3': 'X', 'site1': 'X', 'site8': 'Y', 'site4': 'X', 'site2': 'X', 'site5': 'I2', 'site6': 'I2', 'site7': 'I2'}, {'site8': 'X', 'site5': 'I2', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site4': 'I2', 'site6': 'I2', 'site7': 'I2'}], [(Fraction(6, 1), '9'), (Fraction(3, 10), '12'), (Fraction(3, 1), '5'), (Fraction(3, 4), '2'), (Fraction(6, 7), '12'), (Fraction(-8, 1), '12'), (Fraction(-9, 10), '4'), (Fraction(1, 4), '10'), (Fraction(1, 1), '5'), (Fraction(1, 1), '4'), (Fraction(4, 9), '5'), (Fraction(-1, 1), '2'), (Fraction(4, 9), '14'), (Fraction(-4, 5), '3')]\n",
    "ham_dict = {'2': 2.835697909530385, '3': 4.563938233861004, '4': 9.061058628831027, '5': 8.32944716069347, '6': 6.684243698012364, '7': 5.819053198073945, '8': 8.726491608447832, '9': 6.686432680473677, '10': 7.0935373289106955, '11': 4.444348450120315, '12': 7.854479877498686, '13': 9.703525270953671, '14': 9.802210710023699, '15': 9.712784232553258}\n",
    "leg_dict = {\"site1\": 0, \"site2\": 1, \"site3\": 2, \"site4\": 3, \"site5\": 4, \"site6\": 5, \"site7\": 6, \"site8\": 7,\"site9\": 8}\n",
    "        \n",
    "\n",
    "term_eliminated = 0\n",
    "\n",
    "while True:\n",
    "    error = False\n",
    "    for i in range(len(ham)):\n",
    "        t = ham.pop(i)\n",
    "        c = coeffs.pop(i)\n",
    "        \n",
    "        hamiltonian_temp = construct_hamiltonian(ham,ham_dict,coeffs)\n",
    "        ttns_root = construct_reference_tree()\n",
    "        ham_t = hamiltonian_temp.pad_with_identities(ttns_root)\n",
    "\n",
    "        ttno_ham = ptn.TTNO.from_hamiltonian(ham_t, ttns_root)\n",
    "        total_tensor = ham_t.to_tensor(ttns_root).operator\n",
    "        ttno_svd = ptn.TTNO.from_tensor(ttns_root,\n",
    "                                        total_tensor,\n",
    "                                        leg_dict,\n",
    "                                        mode=ptn.Decomposition.tSVD)\n",
    "        ham_dim = obtain_bond_dimensions(ttno_ham)\n",
    "        svd_dim = obtain_bond_dimensions(ttno_svd)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        if np.any(ham_dim > svd_dim):\n",
    "            error = True\n",
    "            term_eliminated += 1\n",
    "            break\n",
    "        else:\n",
    "            ham.insert(i, t)\n",
    "            coeffs.insert(i, c)\n",
    "        \n",
    "    if not error :\n",
    "        break\n",
    "\n",
    "print(term_eliminated, \" terms eliminated\") \n",
    "print(ham,\" , \",coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham, coeffs = [{'site6': 'I2', 'site1': 'I2', 'site2': 'Y', 'site3': 'I2', 'site4': 'I2', 'site5': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site5': 'I2', 'site8': 'I2', 'site2': 'Y', 'site1': 'X', 'site6': 'I2', 'site4': 'I2', 'site3': 'I2', 'site7': 'I2'}, {'site5': 'I2', 'site3': 'Z', 'site6': 'X', 'site1': 'I2', 'site2': 'I2', 'site4': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site4': 'Y', 'site5': 'X', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site6': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site1': 'X', 'site8': 'X', 'site4': 'Z', 'site7': 'X', 'site3': 'I2', 'site5': 'Z', 'site2': 'I2', 'site6': 'I2'}, {'site3': 'Z', 'site6': 'Z', 'site5': 'Z', 'site1': 'I2', 'site2': 'I2', 'site4': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site6': 'I2', 'site2': 'I2', 'site3': 'Y', 'site1': 'Y', 'site4': 'X', 'site8': 'X', 'site7': 'X', 'site5': 'I2'}, {'site8': 'X', 'site7': 'Z', 'site4': 'Z', 'site2': 'I2', 'site1': 'X', 'site5': 'X', 'site3': 'I2', 'site6': 'I2'}, {'site7': 'I2', 'site8': 'I2', 'site2': 'X', 'site1': 'I2', 'site3': 'I2', 'site4': 'I2', 'site5': 'I2', 'site6': 'I2'}, {'site8': 'X', 'site2': 'Y', 'site1': 'I2', 'site3': 'I2', 'site4': 'I2', 'site5': 'I2', 'site6': 'I2', 'site7': 'I2'}, {'site5': 'Y', 'site7': 'Z', 'site2': 'I2', 'site8': 'Y', 'site4': 'Y', 'site1': 'Y', 'site3': 'X', 'site6': 'I2'}, {'site2': 'Y', 'site3': 'I2', 'site8': 'Z', 'site7': 'Y', 'site5': 'X', 'site1': 'I2', 'site4': 'I2', 'site6': 'I2'}, {'site5': 'Y', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site4': 'I2', 'site6': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site4': 'I2', 'site6': 'Y', 'site3': 'I2', 'site1': 'I2', 'site2': 'I2', 'site5': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site3': 'Z', 'site4': 'I2', 'site6': 'X', 'site2': 'Z', 'site1': 'I2', 'site5': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site2': 'Y', 'site8': 'I2', 'site1': 'Y', 'site6': 'I2', 'site5': 'I2', 'site3': 'I2', 'site4': 'I2', 'site7': 'I2'}, {'site1': 'Z', 'site2': 'Z', 'site4': 'Y', 'site8': 'X', 'site7': 'I2', 'site5': 'X', 'site6': 'X', 'site3': 'I2'}, {'site3': 'Z', 'site6': 'Y', 'site7': 'X', 'site8': 'I2', 'site1': 'Z', 'site2': 'I2', 'site4': 'I2', 'site5': 'I2'}, {'site6': 'X', 'site1': 'I2', 'site2': 'I2', 'site3': 'I2', 'site4': 'I2', 'site5': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site6': 'I2', 'site2': 'I2', 'site7': 'Y', 'site8': 'X', 'site3': 'X', 'site4': 'Z', 'site1': 'I2', 'site5': 'I2'}, {'site2': 'I2', 'site5': 'Z', 'site1': 'Y', 'site7': 'I2', 'site8': 'Y', 'site3': 'Z', 'site4': 'I2', 'site6': 'I2'}, {'site4': 'Y', 'site1': 'Z', 'site6': 'I2', 'site2': 'I2', 'site3': 'I2', 'site5': 'I2', 'site7': 'I2', 'site8': 'I2'}, {'site2': 'Z', 'site8': 'X', 'site3': 'Y', 'site1': 'Y', 'site6': 'Y', 'site5': 'X', 'site4': 'I2', 'site7': 'I2'}], [-3, 1, 3, 3, -1, 5, -3, -4, 1, -3, -3, -5, -3, -4, 5, 2, -3, 1, 2, -1, -4, 5, -3]\n",
    "\n",
    "leg_dict = {\"site1\": 0, \"site2\": 1, \"site3\": 2, \"site4\": 3, \"site5\": 4, \"site6\": 5, \"site7\": 6, \"site8\": 7,\"site9\": 8}\n",
    "        \n",
    "\n",
    "term_eliminated = 0\n",
    "while True:\n",
    "    error = False\n",
    "    for i in range(len(ham)):\n",
    "        t = ham.pop(i)\n",
    "        c = coeffs.pop(i)\n",
    "        hamiltonian_temp = construct_hamiltonian(ham, coeffs)\n",
    "        ttns_root = construct_reference_tree()\n",
    "        ham_t = hamiltonian_temp.pad_with_identities(ttns_root)\n",
    "\n",
    "        ttno_ham = ptn.TTNO.from_hamiltonian(ham_t, ttns_root)\n",
    "        \n",
    "        total_tensor = ham_t.to_tensor(ttns_root).operator\n",
    "        ttno_svd = ptn.TTNO.from_tensor(ttns_root,\n",
    "                                        total_tensor,\n",
    "                                        leg_dict,\n",
    "                                        mode=ptn.Decomposition.tSVD)\n",
    "\n",
    "        contructed_tensor = ttno_ham.completely_contract_tree(to_copy=True)[0]\n",
    "\n",
    "        permutation = []\n",
    "        _find_permutation_rec(ttno_ham, leg_dict, ttno_ham.root_id, permutation)\n",
    "        #print(permutation)\n",
    "        correct_tensor = total_tensor.transpose(permutation)\n",
    "\n",
    "        if not np.allclose(correct_tensor,contructed_tensor):\n",
    "            error = True\n",
    "            term_eliminated += 1\n",
    "            break\n",
    "        else:\n",
    "            ham.insert(i, t)\n",
    "            coeffs.insert(i, c)\n",
    "        \n",
    "    if not error :\n",
    "        break\n",
    "\n",
    "print(term_eliminated, \" terms eliminated\") \n",
    "print(ham, coeffs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
