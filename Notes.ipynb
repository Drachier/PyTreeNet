{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCED or KEEP\n",
    "# TJM :\n",
    "- canonical_form (KEEP)\n",
    "split_qr_contract_r_to_neighbour\n",
    "- move_orthogonalization_cente (KEEP)\n",
    "_move_orth_center_to_neighbour\n",
    "split_qr_contract_r_to_neighbour\n",
    "\n",
    "# TDVP :\n",
    "- _orthogonalize_init (move_orthogonalization_center(KEEP))\n",
    "- _split_updated_site(split_node_qr(KEEP))\n",
    "- _move_orth_and_update_cache_for_path (move_orthogonalization_center(KEEP))\n",
    "\n",
    "# subspace expansion\n",
    "- canonical_form (REDUCED)\n",
    "# chech ttn3.canon\n",
    "# change move_orthogonalization_center to keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_expansion_params(self, params_to_update: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Prompts the user to update specified expansion parameters.\n",
    "    Allows the user to abort the execution gracefully.\n",
    "    Args:\n",
    "        params_to_update (List[str]): List of parameter names to update.\n",
    "            Supports nested parameters using dot notation, e.g., 'SVDParameters.max_bond_dim'.\n",
    "    Returns:\n",
    "        bool: True if the update was successful or skipped, False if the user aborted.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n--- Update Expansion Parameters ---\")\n",
    "    try:\n",
    "        for param in params_to_update:\n",
    "            keys = param.split('.')\n",
    "            current_obj = self.config.Expansion_params\n",
    "            try:\n",
    "                # Traverse nested structures using keys\n",
    "                for key in keys[:-1]:\n",
    "                    if isinstance(current_obj, dict):\n",
    "                        current_obj = current_obj[key]\n",
    "                    else:\n",
    "                        current_obj = getattr(current_obj, key)\n",
    "                \n",
    "                last_key = keys[-1]\n",
    "                \n",
    "                # Retrieve existing value\n",
    "                if isinstance(current_obj, dict):\n",
    "                    existing_value = current_obj[last_key]\n",
    "                else:\n",
    "                    existing_value = getattr(current_obj, last_key)\n",
    "                \n",
    "                # Handle tuple type (e.g., rel_tot_bond)\n",
    "                if isinstance(existing_value, tuple) and len(existing_value) == 2 and all(isinstance(x, (int, float)) for x in existing_value):\n",
    "                    print(f\"Updating '{param}' which is a range (min, max): {existing_value}\")\n",
    "                    \n",
    "                    # Prompt for new min value\n",
    "                    user_input_min = input(f\"Enter new MIN value for '{param}' (current: {existing_value[0]}) or press Enter to keep unchanged: \")\n",
    "                    if user_input_min.strip():\n",
    "                        try:\n",
    "                            new_min = type(existing_value[0])(user_input_min)\n",
    "                        except ValueError:\n",
    "                            print(f\"Invalid input for '{param}' MIN. Keeping the current value: {existing_value[0]}\")\n",
    "                            new_min = existing_value[0]\n",
    "                    else:\n",
    "                        new_min = existing_value[0]\n",
    "                    \n",
    "                    # Prompt for new max value\n",
    "                    user_input_max = input(f\"Enter new MAX value for '{param}' (current: {existing_value[1]}) or press Enter to keep unchanged: \")\n",
    "                    if user_input_max.strip():\n",
    "                        try:\n",
    "                            new_max = type(existing_value[1])(user_input_max)\n",
    "                        except ValueError:\n",
    "                            print(f\"Invalid input for '{param}' MAX. Keeping the current value: {existing_value[1]}\")\n",
    "                            new_max = existing_value[1]\n",
    "                    else:\n",
    "                        new_max = existing_value[1]\n",
    "                    \n",
    "                    # Validate that min < max\n",
    "                    if new_min >= new_max:\n",
    "                        print(f\"Error: For '{param}', MIN ({new_min}) must be less than MAX ({new_max}). Keeping previous values: {existing_value}\")\n",
    "                    else:\n",
    "                        new_tuple = (new_min, new_max)\n",
    "                        if isinstance(current_obj, dict):\n",
    "                            current_obj[last_key] = new_tuple\n",
    "                        else:\n",
    "                            setattr(current_obj, last_key, new_tuple)\n",
    "                        print(f\"Updated '{param}' to {new_tuple}\")\n",
    "                \n",
    "                # Only prompt for numerical values (int, float)\n",
    "                elif isinstance(existing_value, (int, float)):\n",
    "                    user_input = input(f\"Enter new value for '{param}' (current: {existing_value}) or press Enter to keep unchanged: \")\n",
    "                    if user_input.strip():\n",
    "                        try:\n",
    "                            # Convert input to the appropriate type\n",
    "                            new_value = type(existing_value)(user_input)\n",
    "                            if isinstance(current_obj, dict):\n",
    "                                current_obj[last_key] = new_value\n",
    "                            else:\n",
    "                                setattr(current_obj, last_key, new_value)\n",
    "                            print(f\"Updated '{param}' to {new_value}\")\n",
    "                        except ValueError:\n",
    "                            print(f\"Invalid input for '{param}'. Keeping the current value: {existing_value}\")\n",
    "                    else:\n",
    "                        print(f\"Keeping the current value for '{param}': {existing_value}\")\n",
    "                \n",
    "                else:\n",
    "                    print(f\"Skipping update for '{param}' with unsupported type: {type(existing_value).__name__}\")\n",
    "            except (KeyError, AttributeError):\n",
    "                print(f\"Parameter '{param}' not found in config. Skipping.\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n--- Update Aborted by User ---\")\n",
    "        return False  # Indicate that the user aborted the update\n",
    "    print(\"--- Update Complete ---\\n\")\n",
    "    return True  # Indicate that the update was completed successfully\n",
    "\n",
    "def run_ex_with_pause(self, evaluation_time: Union[int, float] = 1, filepath: str = \"\", pgbar: bool = True, interactive: bool = False):\n",
    "    \"\"\"\n",
    "    Runs the expansion process over a number of time steps.\n",
    "\n",
    "    Args:\n",
    "        evaluation_time (Union[int, float], optional): Evaluation duration. Defaults to 1.\n",
    "        filepath (str, optional): Path to save results. Defaults to \"\".\n",
    "        pgbar (bool, optional): If True, shows a progress bar. Defaults to True.\n",
    "        interactive (bool, optional): If True, pauses before each expansion step to update config parameters. Defaults to False.\n",
    "    \"\"\"\n",
    "    self.init_results(evaluation_time)\n",
    "    tol = self.config.Expansion_params[\"tol\"]\n",
    "\n",
    "    for i in self.create_run_tqdm(pgbar):\n",
    "        self.evaluate_and_save_results(evaluation_time, i)\n",
    "        self.run_one_time_step()\n",
    "\n",
    "        # Expansion Step\n",
    "        if (i + 1) % (self.config.Expansion_params[\"expansion_steps\"] + 1) == 0:\n",
    "            if interactive:\n",
    "                print(\"\\n--- Pausing before Expansion Step ---\")\n",
    "                update_success = self.update_expansion_params([\"rel_tot_bond\"])  # Prompt user to update specified config parameters\n",
    "                if not update_success:\n",
    "                    print(\"Aborting the run as per user request.\")\n",
    "                    break  # Exit the loop gracefully\n",
    "                print(\"--- Resuming Execution ---\\n\")\n",
    "\n",
    "            state_ex, tol = self.adjust_tol_and_expand(tol)\n",
    "            self.state = state_ex\n",
    "            self._orthogonalize_init(force_new=True)\n",
    "            self.partial_tree_cache = PartialTreeCachDict()\n",
    "            self.partial_tree_cache = self._init_partial_tree_cache()   \n",
    "\n",
    "        self.record_bond_dimensions()\n",
    "\n",
    "    self.save_results_to_file(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def compute_divergence(self, state1: 'SecondOrderOneSiteTDVP.State', state2: 'SecondOrderOneSiteTDVP.State') -> float:\n",
    "        \"\"\"\n",
    "        Computes the divergence metric between two states.\n",
    "        \"\"\"\n",
    "        expectation1 = expectation_value(state1, self.operators[0])\n",
    "        expectation2 = expectation_value(state2, self.operators[0])\n",
    "        return abs(expectation1 - expectation2)\n",
    "\n",
    "    def get_time_step(self, specific_time) -> int:\n",
    "        \"\"\"\n",
    "        Get the time step index corresponding to a specific time.\n",
    "\n",
    "        Args:\n",
    "            specific_time (Union[int, float]): The specific time for which to get the time step index.\n",
    "\n",
    "        Returns:\n",
    "            int: The time step index corresponding to the specific time.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the specific_time is negative or exceeds the final_time.\n",
    "        \"\"\"\n",
    "        if specific_time > self._final_time:\n",
    "            raise ValueError(\"specific_time cannot exceed final_time.\")\n",
    "\n",
    "        # Calculate the number of steps by performing floor division\n",
    "        time_step_index = floor(specific_time / self._time_step_size)\n",
    "\n",
    "        # Ensure the time_step_index does not exceed the maximum number of steps\n",
    "        max_steps = self._num_time_steps\n",
    "        if time_step_index >= max_steps:\n",
    "            return max_steps - 1  # Adjust to the last valid index\n",
    "        return time_step_index\n",
    "\n",
    "    def _evolve_in_trial(self, new_state = None):   \n",
    "        if new_state is None:\n",
    "            trial_self = deepcopy(self)\n",
    "        else:\n",
    "            trial_self = deepcopy(self)\n",
    "            trial_self.state = new_state\n",
    "        trial_self._orthogonalize_init(force_new=True)\n",
    "        trial_self.partial_tree_cache = PartialTreeCachDict()\n",
    "        trial_self.partial_tree_cache = trial_self._init_partial_tree_cache()\n",
    "        trial_self.run_one_time_step()\n",
    "        return trial_self\n",
    "        \n",
    "    def run_ex(self, evaluation_time: Union[int, float] = 1, filepath: str = \"\", pgbar: bool = True):\n",
    "        \"\"\"\n",
    "        Runs the expansion process over a number of time steps.\n",
    "\n",
    "        Args:\n",
    "            evaluation_time (Union[int, float], optional): Evaluation duration. Defaults to 1.\n",
    "            filepath (str, optional): Path to save results. Defaults to \"\".\n",
    "            pgbar (bool, optional): If True, shows a progress bar. Defaults to True.\n",
    "            interactive (bool, optional): If True, pauses before each expansion step to update config parameters. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.init_results(evaluation_time)\n",
    "        tol = self.config.Expansion_params[\"tol\"]        \n",
    "        use_previous_evolved = False\n",
    "        previous_evolved_expanded = None\n",
    "        should_expand = True\n",
    "\n",
    "        for i  in self.create_run_tqdm(pgbar):\n",
    "            if i < self.get_time_step(self.config.Expansion_params[\"InitExpST\"]) or not should_expand:\n",
    "                self.evaluate_and_save_results(evaluation_time, i)\n",
    "                self.run_one_time_step() \n",
    "                self.accepted_states.append(self.state)\n",
    "                continue\n",
    "\n",
    "            if should_expand:\n",
    "                # Evolve current state\n",
    "                evolved_unexpanded_self = self._evolve_in_trial()\n",
    "\n",
    "                # Expand and evolve\n",
    "                if use_previous_evolved:\n",
    "                    expanded_state = previous_evolved_expanded\n",
    "                else:\n",
    "                    expanded_state, tol, should_expand= self.adjust_tol_and_expand(tol)\n",
    "                    \n",
    "                # Evolve expanded state\n",
    "                evolved_expanded_self = self._evolve_in_trial(expanded_state)\n",
    "\n",
    "                # Compute divergence\n",
    "                divergence = self.compute_divergence(evolved_unexpanded_self.state, evolved_expanded_self.state)\n",
    "\n",
    "                if divergence > self.config.Expansion_params[\"ConvThresh\"]:\n",
    "                    self.__dict__.update(evolved_unexpanded_self.__dict__)\n",
    "                    self.evaluate_and_save_results(evaluation_time, i)\n",
    "                    use_previous_evolved = True\n",
    "                    previous_evolved_expanded = evolved_expanded_self.state\n",
    "                    self.divergence_list.append(divergence)\n",
    "                    self.accepted_states.append(self.state)\n",
    "                    print(divergence)\n",
    "\n",
    "                else:\n",
    "                    print(\"state not converged , divergence:\", divergence)\n",
    "                    trial = 0\n",
    "                    while divergence <= self.config.Expansion_params[\"ConvThresh\"]:\n",
    "                        #self.adjust_rel_tot_bond()\n",
    "                        self.state = expanded_state\n",
    "                        expanded_state, tol, _ = self.adjust_tol_and_expand(tol)\n",
    "                        # Evolve expanded state\n",
    "                        evolved_expanded_self = self._evolve_in_trial(expanded_state)\n",
    "\n",
    "                        divergence = self.compute_divergence(evolved_unexpanded_self.state, evolved_expanded_self.state)\n",
    "                        trial += 1\n",
    "                        print(f\"Trial : {trial} , divergence: {divergence}\")\n",
    "                        if divergence > self.config.Expansion_params[\"ConvThreshUP\"]:\n",
    "                            print(\"state converged after expansion\")\n",
    "                            self.__dict__.update(evolved_expanded_self.__dict__)\n",
    "                            self.evaluate_and_save_results(evaluation_time, i)\n",
    "                            self.divergence_list.append(divergence)\n",
    "                            self.accepted_states.append(self.state)\n",
    "                            break\n",
    "                    use_previous_evolved = False             \n",
    "                # restore the initial rel_tot_bond to initial value        \n",
    "                #self.config.Expansion_params[\"rel_tot_bond\"] = intial_rel_tot_bond \n",
    "                     \n",
    "def run_one_time_step_trial(self, new_state):\n",
    "    \"\"\"\n",
    "    Run a single second order time step.\n",
    "    \n",
    "    This mean we run a full forward and a full backward sweep through the\n",
    "    tree.\n",
    "    \"\"\"\n",
    "    if new_state is None:\n",
    "        trial_self = deepcopy(self)\n",
    "        trial_self.run_one_time_step()\n",
    "    else:    \n",
    "        trial_self = deepcopy(self)\n",
    "        trial_self.state = new_state\n",
    "        trial_self._orthogonalize_init(force_new=True)\n",
    "        trial_self.partial_tree_cache = PartialTreeCachDict()\n",
    "        trial_self.partial_tree_cache = trial_self._init_partial_tree_cache()\n",
    "        trial_self.run_one_time_step()  \n",
    "    return trial_self.state \n",
    "\n",
    "def update_state(self, new_state):\n",
    "    self.state = new_state\n",
    "    self._orthogonalize_init(force_new=True)\n",
    "    self.partial_tree_cache = PartialTreeCachDict()\n",
    "    self.partial_tree_cache = self._init_partial_tree_cache()\n",
    "\n",
    "def run_ex_2(self, evaluation_time: Union[int, float] = 1, filepath: str = \"\", pgbar: bool = True, interactive: bool = False):\n",
    "    \"\"\"\n",
    "    Runs the expansion process over a number of time steps.\n",
    "\n",
    "    Args:\n",
    "        evaluation_time (Union[int, float], optional): Evaluation duration. Defaults to 1.\n",
    "        filepath (str, optional): Path to save results. Defaults to \"\".\n",
    "        pgbar (bool, optional): If True, shows a progress bar. Defaults to True.\n",
    "        interactive (bool, optional): If True, pauses before each expansion step to update config parameters. Defaults to False.\n",
    "    \"\"\"\n",
    "    self.init_results(evaluation_time)       \n",
    "    tol = self.config.Expansion_params[\"tol\"]        \n",
    "    use_previous_evolved = False             \n",
    "    previous_evolved_expanded = None         \n",
    "\n",
    "    for i  in self.create_run_tqdm(pgbar):\n",
    "        if i < self.get_time_step(self.config.Expansion_params[\"InitExpST\"]):\n",
    "            self.evaluate_and_save_results(evaluation_time, i)\n",
    "            self.run_one_time_step() \n",
    "            continue\n",
    "\n",
    "        # Evolve current state\n",
    "        evolved_unexpanded_state = self.run_one_time_step_trial(self.state)\n",
    "\n",
    "        # Expand and evolve\n",
    "        if use_previous_evolved:\n",
    "            expanded_state = previous_evolved_expanded\n",
    "        else:\n",
    "            state = deepcopy(self.state)\n",
    "            expanded_state, tol = adjust_tol_and_expand(state, self.hamiltonian, tol, self.config)\n",
    "            \n",
    "        # Evolve expanded state\n",
    "        evolved_expanded_state = self.run_one_time_step_trial(expanded_state)\n",
    "        \n",
    "        # Compute convergence\n",
    "        convergence = self.compute_convergence(evolved_unexpanded_state, evolved_expanded_state)\n",
    "            \n",
    "        if convergence < self.config.Expansion_params[\"ConvThresh\"]:\n",
    "            use_previous_evolved = True\n",
    "            previous_evolved_expanded = evolved_expanded_state\n",
    "            self.update_state(evolved_unexpanded_state)\n",
    "            self.evaluate_and_save_results(evaluation_time, i)\n",
    "            self.convergence_list.append(convergence)\n",
    "\n",
    "        else:\n",
    "            print(\"state not converged , convergence:\", convergence)\n",
    "            evolved_expanded_state = self.run_one_time_step_trial(expanded_state)\n",
    "\n",
    "            self.update_state(evolved_expanded_state)\n",
    "            self.evaluate_and_save_results(evaluation_time, i)\n",
    "            self.convergence_list.append(convergence)\n",
    "            use_previous_evolved = False           \n",
    "        # restore the initial rel_tot_bond to initial value        \n",
    "        #self.config.Expansion_params[\"rel_tot_bond\"] = intial_rel_tot_bond \n",
    "\n",
    "def run_ex_22(self, evaluation_time: Union[int, float] = 1, filepath: str = \"\", pgbar: bool = True, interactive: bool = False):\n",
    "    \"\"\"\n",
    "    Runs the expansion process over a number of time steps.\n",
    "\n",
    "    Args:\n",
    "        evaluation_time (Union[int, float], optional): Evaluation duration. Defaults to 1.\n",
    "        filepath (str, optional): Path to save results. Defaults to \"\".\n",
    "        pgbar (bool, optional): If True, shows a progress bar. Defaults to True.\n",
    "        interactive (bool, optional): If True, pauses before each expansion step to update config parameters. Defaults to False.\n",
    "    \"\"\"\n",
    "    self.init_results(evaluation_time)       \n",
    "    tol = self.config.Expansion_params[\"tol\"]        \n",
    "    use_previous_evolved = False             \n",
    "    previous_evolved_expanded = None         \n",
    "\n",
    "    for i  in self.create_run_tqdm(pgbar):\n",
    "        if i < self.get_time_step(self.config.Expansion_params[\"InitExpST\"]):\n",
    "            self.evaluate_and_save_results(evaluation_time, i)\n",
    "            self.run_one_time_step() \n",
    "            continue\n",
    "\n",
    "        # Evolve current state\n",
    "        evolved_unexpanded_state , evolved_unexpanded_ptc = self.run_one_time_step_trial()\n",
    "\n",
    "        # Expand and evolve\n",
    "        if use_previous_evolved:\n",
    "            evolved_expanded_state , evolved_expanded_ptc = self.run_one_time_step_trial(previous_evolved_expanded , previous_evolved_expanded_ptc)\n",
    "        else:\n",
    "            state = deepcopy(self.state)\n",
    "            expanded_state, tol = adjust_tol_and_expand(state, self.hamiltonian, tol, self.config)\n",
    "            evolved_expanded_state , evolved_expanded_ptc = self.run_one_time_step_trial(new_state = expanded_state)\n",
    "                        \n",
    "        # Compute convergence\n",
    "        convergence = self.compute_convergence(evolved_unexpanded_state, evolved_expanded_state)\n",
    "            \n",
    "        if convergence < self.config.Expansion_params[\"ConvThresh\"]:\n",
    "            use_previous_evolved = True\n",
    "            previous_evolved_expanded     = evolved_expanded_state\n",
    "            previous_evolved_expanded_ptc = evolved_expanded_ptc\n",
    "            self.state                    = evolved_unexpanded_state\n",
    "            self.partial_tree_cache       = evolved_unexpanded_ptc\n",
    "            self.evaluate_and_save_results(evaluation_time, i)\n",
    "            self.convergence_list.append(convergence)\n",
    "        else:\n",
    "            print(\"state not converged , convergence:\", convergence)\n",
    "            self.state               = evolved_expanded_state\n",
    "            self.partial_tree_cache = evolved_expanded_ptc\n",
    "            self.evaluate_and_save_results(evaluation_time, i)\n",
    "            self.convergence_list.append(convergence)\n",
    "            use_previous_evolved = False\n",
    "        # restore the initial rel_tot_bond to initial value       \n",
    "        #self.config.Expansion_params[\"rel_tot_bond\"] = intial_rel_tot_bond "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
